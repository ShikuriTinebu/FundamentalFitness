{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x99e0aEY_d6"
      },
      "source": [
        "Fundamental Fitness is an AI exercise form correction companion to help users perfect their form in any exercise which they workout with. Our AI uses Google Clouds movenet model to help keep track of 17 points on the user's body to accurately identify and compare their form to that of an expert, as well as help identify what they may need to correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10_zkgbZBkIE"
      },
      "source": [
        "# FundamentalFitness AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u_VGR6_BmbZ"
      },
      "source": [
        "## Base Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtcwSIcgbIVN"
      },
      "outputs": [],
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "!pip install gTTS\n",
        "!pip install JavaScript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BLeJv-pCCld"
      },
      "outputs": [],
      "source": [
        "#Imports (This code was written on google collab, however import files in other code editors as necessary)\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "import matplotlib.patches as patches\n",
        "import imageio\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import io\n",
        "import PIL\n",
        "from IPython.display import display, Javascript, Image, Audio\n",
        "from base64 import b64decode, b64encode\n",
        "from google.colab.output import eval_js\n",
        "import html\n",
        "from gtts import gTTS\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEJBMeRb3YUy"
      },
      "outputs": [],
      "source": [
        "KEYPOINT_DICT = {\n",
        "    'nose': 0,\n",
        "    'left_eye': 1,\n",
        "    'right_eye': 2,\n",
        "    'left_ear': 3,\n",
        "    'right_ear': 4,\n",
        "    'left_shoulder': 5,\n",
        "    'right_shoulder': 6,\n",
        "    'left_elbow': 7,\n",
        "    'right_elbow': 8,\n",
        "    'left_wrist': 9,\n",
        "    'right_wrist': 10,\n",
        "    'left_hip': 11,\n",
        "    'right_hip': 12,\n",
        "    'left_knee': 13,\n",
        "    'right_knee': 14,\n",
        "    'left_ankle': 15,\n",
        "    'right_ankle': 16\n",
        "}\n",
        "\n",
        "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
        "    (0, 1): 'm',\n",
        "    (0, 2): 'c',\n",
        "    (1, 3): 'm',\n",
        "    (2, 4): 'c',\n",
        "    (0, 5): 'm',\n",
        "    (0, 6): 'c',\n",
        "    (5, 7): 'm',\n",
        "    (7, 9): 'm',\n",
        "    (6, 8): 'c',\n",
        "    (8, 10): 'c',\n",
        "    (5, 6): 'y',\n",
        "    (5, 11): 'm',\n",
        "    (6, 12): 'c',\n",
        "    (11, 12): 'y',\n",
        "    (11, 13): 'm',\n",
        "    (13, 15): 'm',\n",
        "    (12, 14): 'c',\n",
        "    (14, 16): 'c'\n",
        "}\n",
        "\n",
        "def _keypoints_and_edges_for_display(keypoints_with_scores,\n",
        "                                     height,\n",
        "                                     width,\n",
        "                                     keypoint_threshold=0.11):\n",
        "  keypoints_all = []\n",
        "  keypoint_edges_all = []\n",
        "  edge_colors = []\n",
        "  num_instances, _, _, _ = keypoints_with_scores.shape\n",
        "  for idx in range(num_instances):\n",
        "    kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
        "    kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
        "    kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
        "    kpts_absolute_xy = np.stack(\n",
        "        [width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
        "    kpts_above_thresh_absolute = kpts_absolute_xy[\n",
        "        kpts_scores > keypoint_threshold, :]\n",
        "    keypoints_all.append(kpts_above_thresh_absolute)\n",
        "\n",
        "    for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n",
        "      if (kpts_scores[edge_pair[0]] > keypoint_threshold and\n",
        "          kpts_scores[edge_pair[1]] > keypoint_threshold):\n",
        "        x_start = kpts_absolute_xy[edge_pair[0], 0]\n",
        "        y_start = kpts_absolute_xy[edge_pair[0], 1]\n",
        "        x_end = kpts_absolute_xy[edge_pair[1], 0]\n",
        "        y_end = kpts_absolute_xy[edge_pair[1], 1]\n",
        "        line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
        "        keypoint_edges_all.append(line_seg)\n",
        "        edge_colors.append(color)\n",
        "  if keypoints_all:\n",
        "    keypoints_xy = np.concatenate(keypoints_all, axis=0)\n",
        "  else:\n",
        "    keypoints_xy = np.zeros((0, 17, 2))\n",
        "\n",
        "  if keypoint_edges_all:\n",
        "    edges_xy = np.stack(keypoint_edges_all, axis=0)\n",
        "  else:\n",
        "    edges_xy = np.zeros((0, 2, 2))\n",
        "\n",
        "  # print(keypoints_xy)\n",
        "  return keypoints_xy, edges_xy, edge_colors\n",
        "\n",
        "\n",
        "def draw_prediction_on_image(\n",
        "    image, keypoints_with_scores, crop_region=None, close_figure=False,\n",
        "    output_image_height=None):\n",
        "  height, width, channel = image.shape\n",
        "  aspect_ratio = float(width) / height\n",
        "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
        "  # To remove the huge white borders\n",
        "  fig.tight_layout(pad=0)\n",
        "  ax.margins(0)\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_xticklabels([])\n",
        "  plt.axis('off')\n",
        "\n",
        "  im = ax.imshow(image)\n",
        "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
        "  ax.add_collection(line_segments)\n",
        "  # Turn off tick labels\n",
        "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
        "\n",
        "  (keypoint_locs, keypoint_edges,\n",
        "   edge_colors) = _keypoints_and_edges_for_display(\n",
        "       keypoints_with_scores, height, width)\n",
        "\n",
        "  line_segments.set_segments(keypoint_edges)\n",
        "  line_segments.set_color(edge_colors)\n",
        "  if keypoint_edges.shape[0]:\n",
        "    line_segments.set_segments(keypoint_edges)\n",
        "    line_segments.set_color(edge_colors)\n",
        "  if keypoint_locs.shape[0]:\n",
        "    scat.set_offsets(keypoint_locs)\n",
        "\n",
        "  if crop_region is not None:\n",
        "    xmin = max(crop_region['x_min'] * width, 0.0)\n",
        "    ymin = max(crop_region['y_min'] * height, 0.0)\n",
        "    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
        "    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
        "    rect = patches.Rectangle(\n",
        "        (xmin,ymin),rec_width,rec_height,\n",
        "        linewidth=1,edgecolor='b',facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "  fig.canvas.draw()\n",
        "  image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "  image_from_plot = image_from_plot.reshape(\n",
        "      fig.canvas.get_width_height()[::-1] + (3,))\n",
        "  plt.close(fig)\n",
        "  if output_image_height is not None:\n",
        "    output_image_width = int(output_image_height / height * width)\n",
        "    image_from_plot = cv2.resize(\n",
        "        image_from_plot, dsize=(output_image_width, output_image_height),\n",
        "         interpolation=cv2.INTER_CUBIC)\n",
        "  return image_from_plot\n",
        "\n",
        "def to_gif(images, duration):\n",
        "  \"\"\"Converts image sequence (4D numpy array) to gif.\"\"\"\n",
        "  imageio.mimsave('./animation.gif', images, duration=duration)\n",
        "  return embed.embed_file('./animation.gif')\n",
        "\n",
        "def progress(value, max=100):\n",
        "  return HTML(\"\"\"\n",
        "      <progress\n",
        "          value='{value}'\n",
        "          max='{max}',\n",
        "          style='width: 100%'\n",
        "      >\n",
        "          {value}\n",
        "      </progress>\n",
        "  \"\"\".format(value=value, max=max))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvrN0iQiOxhR"
      },
      "source": [
        "## Load Movenet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeGHgANcT7a1"
      },
      "outputs": [],
      "source": [
        "model_name = \"movenet_lightning\" #@param [\"movenet_lightning\", \"movenet_thunder\", \"movenet_lightning_f16.tflite\", \"movenet_thunder_f16.tflite\", \"movenet_lightning_int8.tflite\", \"movenet_thunder_int8.tflite\"]\n",
        "\n",
        "if \"tflite\" in model_name:\n",
        "  if \"movenet_lightning_f16\" in model_name:\n",
        "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4?lite-format=tflite\n",
        "    input_size = 192\n",
        "  elif \"movenet_thunder_f16\" in model_name:\n",
        "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n",
        "    input_size = 256\n",
        "  elif \"movenet_lightning_int8\" in model_name:\n",
        "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/int8/4?lite-format=tflite\n",
        "    input_size = 192\n",
        "  elif \"movenet_thunder_int8\" in model_name:\n",
        "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/int8/4?lite-format=tflite\n",
        "    input_size = 256\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported model name: %s\" % model_name)\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  def movenet(input_image):\n",
        "    # TF Lite format expects tensor type of uint8.\n",
        "    input_image = tf.cast(input_image, dtype=tf.uint8)\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_image.numpy())\n",
        "    # Invoke inference.\n",
        "    interpreter.invoke()\n",
        "    # Get the model prediction.\n",
        "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
        "    print(keypoints_with_scores)\n",
        "    return keypoints_with_scores\n",
        "\n",
        "else:\n",
        "  if \"movenet_lightning\" in model_name:\n",
        "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "    input_size = 192\n",
        "  elif \"movenet_thunder\" in model_name:\n",
        "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
        "    input_size = 256\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported model name: %s\" % model_name)\n",
        "\n",
        "  def movenet(input_image):\n",
        "    model = module.signatures['serving_default']\n",
        "\n",
        "    # SavedModel format expects tensor type of int32.\n",
        "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
        "    # Run model inference.\n",
        "    outputs = model(input_image)\n",
        "    # Output is a [1, 1, 17, 3] tensor.\n",
        "    keypoints_with_scores = outputs['output_0'].numpy()\n",
        "    return keypoints_with_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9BY5adcFxJV"
      },
      "source": [
        "Run Program With Live Stream (Squats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S12hLbZOA9hS"
      },
      "outputs": [],
      "source": [
        "#Variables Assignment\n",
        "num_of_faces = 0\n",
        "num_of_pictures_taken = 0\n",
        "minutes_running = 3\n",
        "end_time = time.time() + 60 * minutes_running\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js2img(jsr):\n",
        "  iwizbyts = b64decode(jsr.split(',')[1])\n",
        "  jpgnp = np.frombuffer(iwizbyts, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpgnp, flags=1)\n",
        "  return img\n",
        "def qb2byts(qbra):\n",
        "  qbtablet = PIL.Image.fromarray(qbra, 'RGBA')\n",
        "  strongEyes = io.BytesIO()\n",
        "  qbtablet.save(strongEyes, format='png')\n",
        "  qbbyts = 'data:image/png;base64,{}'.format((str(b64encode(strongEyes.getvalue()), 'utf-8')))\n",
        "  return qbbyts\n",
        "\n",
        "\n",
        "# Functions for starting Stream with Webcam\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var stream;\n",
        "    var video;\n",
        "    var rstrt;\n",
        "    var iwizperiodic;\n",
        "    var div = null;\n",
        "    var unfinished = null;\n",
        "    var stopp = false;\n",
        "    var titleperiodic;\n",
        "\n",
        "    function rmD() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       iwizperiodic = null;\n",
        "       rstrt = null;\n",
        "       titleperiodic = null;\n",
        "    }\n",
        "\n",
        "    function animeFr() {\n",
        "      if (!stopp) {\n",
        "        window.requestAnimationFrame(animeFr);\n",
        "      }\n",
        "      if (unfinished) {\n",
        "        var mark = \"\";\n",
        "        if (!stopp) {\n",
        "          rstrt.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          mark = rstrt.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var pl = unfinished;\n",
        "        unfinished = null;\n",
        "        pl(mark);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function crD() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const mohit = document.createElement('div');\n",
        "      mohit.innerHTML = \"<span>Status:</span>\";\n",
        "      titleperiodic = document.createElement('span');\n",
        "      titleperiodic.innerText = 'No data';\n",
        "      titleperiodic.style.fontWeight = 'bold';\n",
        "      mohit.appendChild(titleperiodic);\n",
        "      div.appendChild(mohit);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { stopp = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      iwizperiodic = document.createElement('img');\n",
        "      iwizperiodic.style.position = 'absolute';\n",
        "      iwizperiodic.style.zIndex = 1;\n",
        "      iwizperiodic.onclick = () => { stopp = true; };\n",
        "      div.appendChild(iwizperiodic);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'Click on the video or this text to end</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { stopp = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      rstrt = document.createElement('canvas');\n",
        "      rstrt.width = 640; //video.videoWidth;\n",
        "      rstrt.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(animeFr);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (stopp) {\n",
        "        rmD();\n",
        "        stopp = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await crD();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        titleperiodic.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        iwizperiodic.style.top = videoRect.top + \"px\";\n",
        "        iwizperiodic.style.left = videoRect.left + \"px\";\n",
        "        iwizperiodic.style.width = videoRect.width + \"px\";\n",
        "        iwizperiodic.style.height = videoRect.height + \"px\";\n",
        "        iwizperiodic.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var mark = await new Promise(function(resolve, reject) {\n",
        "        unfinished = resolve;\n",
        "      });\n",
        "      stopp = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': mark};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "# Manipulates in the input data\n",
        "def normalize(L):\n",
        "  # given a list of numbers L, normalize it so all examples are\n",
        "  # treated on a commensurate basis\n",
        "\n",
        "  totalLength = 0\n",
        "  centered_x = 0\n",
        "  centered_y = 0\n",
        "\n",
        "  for i in range(17):\n",
        "    x_i = L[2 * i + 1]\n",
        "    y_i = L[2 * i + 1 + 1]\n",
        "\n",
        "    centered_x += x_i\n",
        "    centered_y += y_i\n",
        "\n",
        "  centered_x /= 17\n",
        "  centered_y /= 17\n",
        "  # print(str(centered_x) + \" \" + str(centered_y))\n",
        "\n",
        "  for i in range(17):\n",
        "    x_i = L[2 * i + 1] - centered_x\n",
        "    y_i = L[2 * i + 1 + 1] - centered_y\n",
        "\n",
        "    totalLength += np.sqrt(x_i**2 + y_i**2)\n",
        "\n",
        "  answer = []\n",
        "  answer.append(L[0])\n",
        "\n",
        "  checkerLength = 0\n",
        "\n",
        "  for i in range(17):\n",
        "    x_i = L[2 * i + 1] - centered_x\n",
        "    y_i = L[2 * i + 1 + 1] - centered_y\n",
        "\n",
        "    localLength = np.sqrt(x_i**2 + y_i**2)\n",
        "    vectorLength = localLength / totalLength\n",
        "\n",
        "    unitVectorX_i = x_i / localLength\n",
        "    unitVectorY_i = y_i / localLength\n",
        "\n",
        "    answer.append(unitVectorX_i * vectorLength)\n",
        "    answer.append(unitVectorY_i * vectorLength)\n",
        "    checkerLength += vectorLength\n",
        "\n",
        "  return answer\n",
        "\n",
        "W = [-4.325657666816052, 0.08950988296523274, 0.2602615118602717, 0.09168778116347012, 0.2833736578201197, 0.08851209244449602, 0.2730213068764441, 0.03377786910176586, 0.2829417705077817, 0.044586852917931206, 0.28011183885977026, -0.056148143356378015, 0.18864196696604113, -0.02903514855283025, 0.19045440244384626, 0.018195586510948762, 0.01261177001665899, 0.03788696504963289, 0.03959836340755398, 0.12405132448563677, -0.0004533561232031207, 0.11884561233286743, 0.00893631774601232, -0.21652737025209765, -0.13717378206275407, -0.17609551346401248, -0.11537971424494572, 0.024653062721093397, -0.25369415095237674, 0.042377792711076015, -0.22879769502099515, -0.129253889915888, -0.5657603309523151, -0.10701182719630813, -0.5186349668198829]\n",
        "P = [-3.416517163139581, -21.35578982291039, 15.294807287857722, -0.04446693184347948, 17.654806670742797, -21.405631908319723, 16.747640832754694, -0.006437738462491961, 11.96924658098809, -18.395037143828063, 10.38748343415219, -2.220676834411694, -2.7379735227710653, -1.887111081873324, -5.867522019037623, 10.692063278138463, 9.24797879387239, 8.8881291018652, 2.0018978882708645, 10.232955313849718, -16.92051006100624, 10.4495186854179, -13.42190284613647, -19.523003680479434, 16.79710045762282, 0.2498507719518179, 16.40767254150967, -17.499930083863376, 19.49555831355778, -0.4482036419241091, 19.620184048129254, -10.181590096181084, 15.884887923153764, -9.069319310498997, 15.56784735525869]\n",
        "# we train S?\n",
        "# W = []\n",
        "\n",
        "\n",
        "# Computes the probability as a percent that the squat is good given a normalized L\n",
        "def probability(L):\n",
        "  dot_product = 0\n",
        "  for i in range(0, 35):\n",
        "    dot_product += L[i] * W[i]\n",
        "\n",
        "  output = 1/(1 + np.exp(dot_product)) * 100\n",
        "  output = (output - 99)/1 * 20 * 2.5 * 100\n",
        "\n",
        "  if output < 0:\n",
        "    output = 0\n",
        "\n",
        "  if output > 100:\n",
        "    output = 100\n",
        "\n",
        "  return output\n",
        "\n",
        "def probabilityPlank(L):\n",
        "  dot_product = 0\n",
        "  for i in range(0, 35):\n",
        "    dot_product += L[i] * P[i]\n",
        "\n",
        "  output = 1/(1 + np.exp(dot_product)) * 100\n",
        "\n",
        "  return output\n",
        "\n",
        "#Python Speech Function\n",
        "def speak(text: str):\n",
        "    tts = gTTS(text=text, lang=\"en\")\n",
        "    filename = \"sound.mp3\"\n",
        "    tts.save(filename)\n",
        "    Audio(filename, autoplay = True)\n",
        "\n",
        "#Start Code\n",
        "video_stream()\n",
        "label_html = 'Live Stream is running...'\n",
        "bbox = ''\n",
        "count = 0\n",
        "img_array = []\n",
        "running_sum = 0\n",
        "running_count = 0\n",
        "\n",
        "while (time.time() < end_time):\n",
        "    jsr = video_frame(label_html, bbox)\n",
        "    if not jsr:\n",
        "        break\n",
        "    image = js2img(jsr[\"img\"])\n",
        "    # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
        "    input_image = tf.expand_dims(image, axis=0)\n",
        "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
        "\n",
        "    # Run model inference.\n",
        "    keypoints_with_scores = movenet(input_image)\n",
        "    # print(keypoints_with_scores)\n",
        "\n",
        "    # Visualize the predictions with image.\n",
        "    display_image = tf.expand_dims(image, axis=0)\n",
        "    display_image = tf.cast(tf.image.resize_with_pad(\n",
        "        display_image, 1280, 1280), dtype=tf.int32)\n",
        "    output_overlay = draw_prediction_on_image(\n",
        "        np.squeeze(display_image.numpy(), axis=0), keypoints_with_scores)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    img_array.append(output_overlay)\n",
        "    plt.imshow(output_overlay)\n",
        "\n",
        "    keypointsxy = _keypoints_and_edges_for_display(keypoints_with_scores, 1280, 1280)[0]\n",
        "    flattendList = []\n",
        "    flattendList.append(1)\n",
        "\n",
        "    for i in range(17):\n",
        "      for j in range(2):\n",
        "        if len(keypointsxy) > i:\n",
        "          flattendList.append(keypointsxy[i][j])\n",
        "\n",
        "\n",
        "    if len(flattendList) != 35:\n",
        "      lastX = flattendList[len(flattendList)-2]\n",
        "      lastY = flattendList[len(flattendList)-1]\n",
        "      while len(flattendList) < 35:\n",
        "        epsilon = np.random.rand()\n",
        "        flattendList.append(lastX + epsilon)\n",
        "        flattendList.append(lastY + epsilon)\n",
        "    regularizedList = normalize(flattendList)\n",
        "    goal = probability(regularizedList)\n",
        "    print(goal)\n",
        "    if goal > 30:\n",
        "      running_count += 1\n",
        "      running_sum += goal\n",
        "\n",
        "    print(len(flattendList))\n",
        "    print(flattendList)\n",
        "\n",
        "    _ = plt.axis('off')\n",
        "x = 0\n",
        "if running_count != 0:\n",
        "  x = float(running_sum/running_count)\n",
        "\n",
        "val = str('%.2f'%(x))\n",
        "text = \"Your squat form was scored as \" + val + \" percent of perfection\"\n",
        "print(text)\n",
        "\n",
        "\n",
        "for i in range(len(img_array)):\n",
        "   img = img_array[i]\n",
        "   height, width, layers = img.shape\n",
        "   size = (width,height)\n",
        "out = cv2.VideoWriter('video.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(img_array)):\n",
        "   out.write(img_array[i])\n",
        "out.release()\n",
        "\n",
        "tts = gTTS(text=text, lang=\"en\")\n",
        "filename = \"sound.mp3\"\n",
        "tts.save(filename)\n",
        "Audio(filename, autoplay = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Program with Live Stream (plank)"
      ],
      "metadata": {
        "id": "IgYyDoIYd7Ji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXt5DZNbwn5P"
      },
      "outputs": [],
      "source": [
        "#Variables Assignment\n",
        "num_of_faces = 0\n",
        "num_of_pictures_taken = 0\n",
        "minutes_running = 3\n",
        "end_time = time.time() + 60 * minutes_running\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js2img(jsr):\n",
        "  iwizbyts = b64decode(jsr.split(',')[1])\n",
        "  jpgnp = np.frombuffer(iwizbyts, dtype=np.uint8)\n",
        "  img = cv2.imdecode(jpgnp, flags=1)\n",
        "  return img\n",
        "def qb2byts(qbra):\n",
        "  qbtablet = PIL.Image.fromarray(qbra, 'RGBA')\n",
        "  strongEyes = io.BytesIO()\n",
        "  qbtablet.save(strongEyes, format='png')\n",
        "  qbbyts = 'data:image/png;base64,{}'.format((str(b64encode(strongEyes.getvalue()), 'utf-8')))\n",
        "  return qbbyts\n",
        "\n",
        "\n",
        "# Functions for starting Stream with Webcam\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var stream;\n",
        "    var video;\n",
        "    var rstrt;\n",
        "    var iwizperiodic;\n",
        "    var div = null;\n",
        "    var unfinished = null;\n",
        "    var stopp = false;\n",
        "    var titleperiodic;\n",
        "\n",
        "    function rmD() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       iwizperiodic = null;\n",
        "       rstrt = null;\n",
        "       titleperiodic = null;\n",
        "    }\n",
        "\n",
        "    function animeFr() {\n",
        "      if (!stopp) {\n",
        "        window.requestAnimationFrame(animeFr);\n",
        "      }\n",
        "      if (unfinished) {\n",
        "        var mark = \"\";\n",
        "        if (!stopp) {\n",
        "          rstrt.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          mark = rstrt.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var pl = unfinished;\n",
        "        unfinished = null;\n",
        "        pl(mark);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function crD() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const mohit = document.createElement('div');\n",
        "      mohit.innerHTML = \"<span>Status:</span>\";\n",
        "      titleperiodic = document.createElement('span');\n",
        "      titleperiodic.innerText = 'No data';\n",
        "      titleperiodic.style.fontWeight = 'bold';\n",
        "      mohit.appendChild(titleperiodic);\n",
        "      div.appendChild(mohit);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { stopp = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      iwizperiodic = document.createElement('img');\n",
        "      iwizperiodic.style.position = 'absolute';\n",
        "      iwizperiodic.style.zIndex = 1;\n",
        "      iwizperiodic.onclick = () => { stopp = true; };\n",
        "      div.appendChild(iwizperiodic);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'Click on the video or this text to end</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { stopp = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      rstrt = document.createElement('canvas');\n",
        "      rstrt.width = 640; //video.videoWidth;\n",
        "      rstrt.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(animeFr);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (stopp) {\n",
        "        rmD();\n",
        "        stopp = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await crD();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        titleperiodic.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        iwizperiodic.style.top = videoRect.top + \"px\";\n",
        "        iwizperiodic.style.left = videoRect.left + \"px\";\n",
        "        iwizperiodic.style.width = videoRect.width + \"px\";\n",
        "        iwizperiodic.style.height = videoRect.height + \"px\";\n",
        "        iwizperiodic.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var mark = await new Promise(function(resolve, reject) {\n",
        "        unfinished = resolve;\n",
        "      });\n",
        "      stopp = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': mark};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "# Manipulates in the input data\n",
        "def normalize(L):\n",
        "  # given a list of numbers L, normalize it so all examples are\n",
        "  # treated on a commensurate basis\n",
        "\n",
        "  totalLength = 0\n",
        "  centered_x = 0\n",
        "  centered_y = 0\n",
        "\n",
        "  for i in range(17):\n",
        "    x_i = L[2 * i + 1]\n",
        "    y_i = L[2 * i + 1 + 1]\n",
        "\n",
        "    centered_x += x_i\n",
        "    centered_y += y_i\n",
        "\n",
        "  centered_x /= 17\n",
        "  centered_y /= 17\n",
        "  # print(str(centered_x) + \" \" + str(centered_y))\n",
        "\n",
        "  for i in range(17):\n",
        "    x_i = L[2 * i + 1] - centered_x\n",
        "    y_i = L[2 * i + 1 + 1] - centered_y\n",
        "\n",
        "    totalLength += np.sqrt(x_i**2 + y_i**2)\n",
        "\n",
        "  answer = []\n",
        "  answer.append(L[0])\n",
        "\n",
        "  checkerLength = 0\n",
        "\n",
        "  for i in range(17):\n",
        "    x_i = L[2 * i + 1] - centered_x\n",
        "    y_i = L[2 * i + 1 + 1] - centered_y\n",
        "\n",
        "    localLength = np.sqrt(x_i**2 + y_i**2)\n",
        "    vectorLength = localLength / totalLength\n",
        "\n",
        "    unitVectorX_i = x_i / localLength\n",
        "    unitVectorY_i = y_i / localLength\n",
        "\n",
        "    answer.append(unitVectorX_i * vectorLength)\n",
        "    answer.append(unitVectorY_i * vectorLength)\n",
        "    checkerLength += vectorLength\n",
        "\n",
        "  return answer\n",
        "\n",
        "W = [-4.325657666816052, 0.08950988296523274, 0.2602615118602717, 0.09168778116347012, 0.2833736578201197, 0.08851209244449602, 0.2730213068764441, 0.03377786910176586, 0.2829417705077817, 0.044586852917931206, 0.28011183885977026, -0.056148143356378015, 0.18864196696604113, -0.02903514855283025, 0.19045440244384626, 0.018195586510948762, 0.01261177001665899, 0.03788696504963289, 0.03959836340755398, 0.12405132448563677, -0.0004533561232031207, 0.11884561233286743, 0.00893631774601232, -0.21652737025209765, -0.13717378206275407, -0.17609551346401248, -0.11537971424494572, 0.024653062721093397, -0.25369415095237674, 0.042377792711076015, -0.22879769502099515, -0.129253889915888, -0.5657603309523151, -0.10701182719630813, -0.5186349668198829]\n",
        "P = [-3.416517163139581, -21.35578982291039, 15.294807287857722, -0.04446693184347948, 17.654806670742797, -21.405631908319723, 16.747640832754694, -0.006437738462491961, 11.96924658098809, -18.395037143828063, 10.38748343415219, -2.220676834411694, -2.7379735227710653, -1.887111081873324, -5.867522019037623, 10.692063278138463, 9.24797879387239, 8.8881291018652, 2.0018978882708645, 10.232955313849718, -16.92051006100624, 10.4495186854179, -13.42190284613647, -19.523003680479434, 16.79710045762282, 0.2498507719518179, 16.40767254150967, -17.499930083863376, 19.49555831355778, -0.4482036419241091, 19.620184048129254, -10.181590096181084, 15.884887923153764, -9.069319310498997, 15.56784735525869]\n",
        "# we train S?\n",
        "# W = []\n",
        "\n",
        "\n",
        "# Computes the probability as a percent that the squat is good given a normalized L\n",
        "def probability(L):\n",
        "  dot_product = 0\n",
        "  for i in range(0, 35):\n",
        "    dot_product += L[i] * W[i]\n",
        "\n",
        "  output = 1/(1 + np.exp(dot_product)) * 100\n",
        "  output = (output - 99)/1 * 20 * 2.5 * 100\n",
        "\n",
        "  if output < 0:\n",
        "    output = 0\n",
        "\n",
        "  if output > 100:\n",
        "    output = 100\n",
        "\n",
        "  return output\n",
        "\n",
        "def probabilityPlank(L):\n",
        "  dot_product = 0\n",
        "  for i in range(0, 35):\n",
        "    dot_product += L[i] * P[i]\n",
        "\n",
        "  output = 1/(1 + np.exp(dot_product)) * 100\n",
        "\n",
        "  return output\n",
        "\n",
        "#Python Speech Function\n",
        "def speak(text: str):\n",
        "    tts = gTTS(text=text, lang=\"en\")\n",
        "    filename = \"sound.mp3\"\n",
        "    tts.save(filename)\n",
        "    Audio(filename, autoplay = True)\n",
        "\n",
        "#Start Code\n",
        "video_stream()\n",
        "label_html = 'Live Stream is running...'\n",
        "bbox = ''\n",
        "count = 0\n",
        "img_array = []\n",
        "running_sum = 0\n",
        "running_count = 0\n",
        "\n",
        "while (time.time() < end_time):\n",
        "    jsr = video_frame(label_html, bbox)\n",
        "    if not jsr:\n",
        "        break\n",
        "    image = js2img(jsr[\"img\"])\n",
        "    # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
        "    input_image = tf.expand_dims(image, axis=0)\n",
        "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
        "\n",
        "    # Run model inference.\n",
        "    keypoints_with_scores = movenet(input_image)\n",
        "    # print(keypoints_with_scores)\n",
        "\n",
        "    # Visualize the predictions with image.\n",
        "    display_image = tf.expand_dims(image, axis=0)\n",
        "    display_image = tf.cast(tf.image.resize_with_pad(\n",
        "        display_image, 1280, 1280), dtype=tf.int32)\n",
        "    output_overlay = draw_prediction_on_image(\n",
        "        np.squeeze(display_image.numpy(), axis=0), keypoints_with_scores)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    img_array.append(output_overlay)\n",
        "    plt.imshow(output_overlay)\n",
        "\n",
        "    keypointsxy = _keypoints_and_edges_for_display(keypoints_with_scores, 1280, 1280)[0]\n",
        "    flattendList = []\n",
        "    flattendList.append(1)\n",
        "\n",
        "    for i in range(17):\n",
        "      for j in range(2):\n",
        "        if len(keypointsxy) > i:\n",
        "          flattendList.append(keypointsxy[i][j])\n",
        "\n",
        "\n",
        "    if len(flattendList) != 35:\n",
        "      lastX = flattendList[len(flattendList)-2]\n",
        "      lastY = flattendList[len(flattendList)-1]\n",
        "      while len(flattendList) < 35:\n",
        "        epsilon = np.random.rand()\n",
        "        flattendList.append(lastX + epsilon)\n",
        "        flattendList.append(lastY + epsilon)\n",
        "    regularizedList = normalize(flattendList)\n",
        "    goal = probabilityPlank(regularizedList)\n",
        "    print(goal)\n",
        "    if goal > 30:\n",
        "      running_count += 1\n",
        "      running_sum += goal\n",
        "\n",
        "    print(len(flattendList))\n",
        "    print(flattendList)\n",
        "\n",
        "    _ = plt.axis('off')\n",
        "x = 0\n",
        "if running_count != 0:\n",
        "  x = float(running_sum/running_count)\n",
        "\n",
        "val = str('%.2f'%(x))\n",
        "text = \"Your plank form was scored as \" + val + \" percent of perfection\"\n",
        "print(text)\n",
        "\n",
        "\n",
        "for i in range(len(img_array)):\n",
        "   img = img_array[i]\n",
        "   height, width, layers = img.shape\n",
        "   size = (width,height)\n",
        "out = cv2.VideoWriter('video.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(img_array)):\n",
        "   out.write(img_array[i])\n",
        "out.release()\n",
        "\n",
        "tts = gTTS(text=text, lang=\"en\")\n",
        "filename = \"sound.mp3\"\n",
        "tts.save(filename)\n",
        "Audio(filename, autoplay = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}